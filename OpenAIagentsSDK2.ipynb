{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzhtIOtDPbm61CTvNC/sCw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodewithTanzeel/OpenAi-Agents-SDK/blob/main/OpenAIagentsSDK2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vyXPwIi33vIa",
        "outputId": "5bde1159-4a64-460a-d673-c340c564e980"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.2.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.8.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting mcp<2,>=1.11.0 (from openai-agents)\n",
            "  Downloading mcp-1.12.1-py3-none-any.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai<2,>=1.96.1 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (1.97.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.32.3)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (4.14.1)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.9.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.0)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading sse_starlette-2.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.47.2)\n",
            "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.96.1->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.96.1->openai-agents) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.96.1->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.96.1->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.26.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp<2,>=1.11.0->openai-agents) (8.2.1)\n",
            "Downloading openai_agents-0.2.3-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.4/161.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.8.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.12.1-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.5/158.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-2.4.1-py3-none-any.whl (10 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, python-dotenv, httpx-sse, colorama, sse-starlette, griffe, pydantic-settings, mcp, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.8.0 httpx-sse-0.4.1 mcp-1.12.1 openai-agents-0.2.3 pydantic-settings-2.10.1 python-dotenv-1.1.1 sse-starlette-2.4.1 types-requests-2.32.4.20250611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "nUXPuDuB3zAW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "KrVb7uucBSJm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "2_QNGPQBBS1K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "external_client:AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model:OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    openai_client=external_client\n",
        ")"
      ],
      "metadata": {
        "id": "JeCgS4nCBW6u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **AGENT** **LEVEL**"
      ],
      "metadata": {
        "id": "I-7OwwTGd-FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, OpenAIChatCompletionsModel, Runner, set_tracing_disabled\n",
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "async def main():\n",
        "    # This agent will use the custom LLM provider\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in haikus.\",\n",
        "        model=OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=client),\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        agent,\n",
        "        \"Tell me about aggregation in programming.\",\n",
        "    )\n",
        "    print(result.final_output)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay92VrpxBfUs",
        "outputId": "a6056dfa-984c-412a-d6bd-59a38f26d52e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parts form a larger\n",
            "Whole, but stand alone as well,\n",
            "Objects coexist.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RUN LEVEL**"
      ],
      "metadata": {
        "id": "p9M56nzxgmG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "\n",
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "agent: Agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "result = Runner.run_sync(agent, \"Tell me about GEMINI MODELS.\", run_config=config)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVEuhpDiD9IQ",
        "outputId": "806c9710-5074-4ad5-ad87-ba04187774ce"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunResult:\n",
            "- Last agent: Agent(name=\"Assistant\", ...)\n",
            "- Final output (str):\n",
            "    Okay, let's delve into the Gemini models. Gemini is a family of multimodal large language models (LLMs) developed by Google AI. They are designed to be highly versatile and capable of handling various types of information, including text, images, audio, video, and code.  Here's a breakdown of key aspects:\n",
            "    \n",
            "    **Key Features and Capabilities:**\n",
            "    \n",
            "    *   **Multimodality:** This is Gemini's defining characteristic. Unlike models trained on primarily text, Gemini is natively multimodal, meaning it's trained from the ground up to understand and reason across different types of data. This allows it to:\n",
            "        *   **Reason about images:**  Understand the content of images, identify objects, and answer questions about visual scenes.\n",
            "        *   **Comprehend audio:** Process and understand spoken language, music, and other sounds.\n",
            "        *   **Analyze video:** Understand the sequence of events in a video, identify objects and actions, and answer questions about video content.\n",
            "        *   **Generate code:**  Write, debug, and explain code in various programming languages.\n",
            "    \n",
            "    *   **Reasoning and Problem Solving:** Gemini models are designed for advanced reasoning capabilities. They can:\n",
            "        *   Solve complex problems that require integrating information from multiple sources.\n",
            "        *   Perform logical deduction and inference.\n",
            "        *   Understand and generate nuanced responses.\n",
            "        *   Learn in-context.\n",
            "    \n",
            "    *   **Different Sizes/Versions:** Google offers different sizes of Gemini models to cater to various needs and hardware constraints. The most commonly known are:\n",
            "        *   **Gemini Ultra:** The largest and most capable model, designed for highly complex tasks.  Intended for data centers and enterprise applications.\n",
            "        *   **Gemini Pro:** A more balanced model, suitable for a wide range of tasks and applications. Powers many of Google's AI features, including Bard (now Gemini).\n",
            "        *   **Gemini Nano:** The smallest model, designed for on-device use on smartphones and other mobile devices. Enables AI features that run directly on your device, even without an internet connection.\n",
            "    \n",
            "    *   **Integration with Google Products:** Gemini is deeply integrated into Google's ecosystem, powering various products and services, including:\n",
            "        *   **Gemini (formerly Bard):** Google's conversational AI chatbot, similar to ChatGPT.\n",
            "        *   **Pixel phones:** Gemini Nano enables features like Smart Reply in messaging apps and Summarize in the Recorder app.\n",
            "        *   **Google Cloud:** Gemini models are available through Google Cloud Vertex AI, allowing developers and businesses to build AI-powered applications.\n",
            "    \n",
            "    **Key Advantages of a Multimodal Approach:**\n",
            "    \n",
            "    *   **Improved Understanding:** By processing information from multiple modalities, Gemini can gain a more complete and nuanced understanding of the world.\n",
            "    *   **More Natural Interactions:**  Multimodality allows for more natural and intuitive interactions with AI systems, as humans naturally communicate using a combination of text, images, and sounds.\n",
            "    *   **New Possibilities:** Opens up possibilities for new AI applications that were previously impossible with text-only models.\n",
            "    \n",
            "    **Examples of Applications:**\n",
            "    \n",
            "    *   **Image and Video Analysis:**  Analyzing medical images to detect diseases, identifying objects in surveillance videos, creating automated video summaries.\n",
            "    *   **Code Generation and Debugging:**  Assisting developers with writing and debugging code, generating code from natural language descriptions.\n",
            "    *   **Content Creation:** Generating creative content, such as writing stories, composing music, and creating images.\n",
            "    *   **Personalized Recommendations:** Providing personalized recommendations based on a user's preferences and interests across different modalities.\n",
            "    *   **Education:** Creating interactive learning experiences that combine text, images, and audio.\n",
            "    \n",
            "    **How it Differs from Other LLMs (like GPT):**\n",
            "    \n",
            "    *   **Native Multimodality:** While other LLMs can sometimes process images or audio through separate modules or plugins, Gemini is designed from the ground up to be multimodal. This leads to better performance and efficiency when working with diverse data types.\n",
            "    \n",
            "    *   **Focus on Reasoning:** Gemini is explicitly designed for advanced reasoning capabilities.\n",
            "    \n",
            "    **Ethical Considerations:**\n",
            "    \n",
            "    As with any powerful AI technology, there are ethical considerations surrounding Gemini, including:\n",
            "    \n",
            "    *   **Bias:** Ensuring that the models are not biased against certain groups of people.\n",
            "    *   **Misinformation:** Preventing the models from being used to generate and spread misinformation.\n",
            "    *   **Privacy:** Protecting user privacy when collecting and processing data.\n",
            "    *   **Job Displacement:** Addressing the potential impact of AI on employment.\n",
            "    \n",
            "    **In summary, Gemini represents a significant step forward in the development of AI. Its multimodal capabilities, advanced reasoning skills, and integration with Google's ecosystem make it a powerful tool for a wide range of applications.**\n",
            "- 1 new item(s)\n",
            "- 1 raw response(s)\n",
            "- 0 input guardrail result(s)\n",
            "- 0 output guardrail result(s)\n",
            "(See `RunResult` for more details)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GLOBAL**"
      ],
      "metadata": {
        "id": "ZMt0jTolgsW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, AsyncOpenAI, set_default_openai_client, set_tracing_disabled, set_default_openai_api\n",
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "set_tracing_disabled(True)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "set_default_openai_client(external_client)\n",
        "\n",
        "agent: Agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\", model=\"gemini-2.5-flash\")\n",
        "\n",
        "result = Runner.run_sync(agent, \"Hello\")\n",
        "\n",
        "\n",
        "# print(result)\n",
        "result.raw_responses\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ5Ngx-Te2wC",
        "outputId": "ea52ba9b-debe-4469-b0c9-4f94d6a6b995"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='Hello! How can I help you today?', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=8, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=9, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=41), response_id=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}